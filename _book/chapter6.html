<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Introduction to statistical inference | Introduction to quantitative methods for economists</title>
  <meta name="description" content="This online introductory textbook offers the essential coding and quantitative skills to students in economics and social sciences in general." />
  <meta name="generator" content="bookdown 0.27 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Introduction to statistical inference | Introduction to quantitative methods for economists" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This online introductory textbook offers the essential coding and quantitative skills to students in economics and social sciences in general." />
  <meta name="github-repo" content="Alessandro1984/Intro_to_quant_methods" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Introduction to statistical inference | Introduction to quantitative methods for economists" />
  
  <meta name="twitter:description" content="This online introductory textbook offers the essential coding and quantitative skills to students in economics and social sciences in general." />
  

<meta name="author" content="Alessandro Bramucci" />


<meta name="date" content="2022-09-14" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="chapter5.html"/>
<link rel="next" href="chapter7.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo"><a href="./"><img src="images/logo.png"></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About this book</a></li>
<li class="part"><span><b>I Introduction to R</b></span></li>
<li class="chapter" data-level="1" data-path="chapter1.html"><a href="chapter1.html"><i class="fa fa-check"></i><b>1</b> Language essentials</a>
<ul>
<li class="chapter" data-level="1.1" data-path="chapter1.html"><a href="chapter1.html#why-r"><i class="fa fa-check"></i><b>1.1</b> Why R?</a></li>
<li class="chapter" data-level="1.2" data-path="chapter1.html"><a href="chapter1.html#r-and-rstudio"><i class="fa fa-check"></i><b>1.2</b> R and RStudio</a></li>
<li class="chapter" data-level="1.3" data-path="chapter1.html"><a href="chapter1.html#basic-operations"><i class="fa fa-check"></i><b>1.3</b> Basic operations</a></li>
<li class="chapter" data-level="1.4" data-path="chapter1.html"><a href="chapter1.html#basic-data-structures"><i class="fa fa-check"></i><b>1.4</b> Basic data structures</a></li>
<li class="chapter" data-level="1.5" data-path="chapter1.html"><a href="chapter1.html#if-else-statement"><i class="fa fa-check"></i><b>1.5</b> if else statement</a></li>
<li class="chapter" data-level="1.6" data-path="chapter1.html"><a href="chapter1.html#for-loops"><i class="fa fa-check"></i><b>1.6</b> For loops</a></li>
<li class="chapter" data-level="1.7" data-path="chapter1.html"><a href="chapter1.html#nested-loops"><i class="fa fa-check"></i><b>1.7</b> Nested loops</a></li>
<li class="chapter" data-level="1.8" data-path="chapter1.html"><a href="chapter1.html#simple-functions"><i class="fa fa-check"></i><b>1.8</b> Simple functions</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapter2.html"><a href="chapter2.html"><i class="fa fa-check"></i><b>2</b> Data extraction and manipulation</a>
<ul>
<li class="chapter" data-level="2.1" data-path="chapter2.html"><a href="chapter2.html#conditional-selection"><i class="fa fa-check"></i><b>2.1</b> Conditional selection</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chapter3.html"><a href="chapter3.html"><i class="fa fa-check"></i><b>3</b> Application</a>
<ul>
<li class="chapter" data-level="3.1" data-path="chapter3.html"><a href="chapter3.html#contributions-to-gdp-growth"><i class="fa fa-check"></i><b>3.1</b> Contributions to GDP growth</a></li>
<li class="chapter" data-level="3.2" data-path="chapter3.html"><a href="chapter3.html#pulling-and-filtering-data"><i class="fa fa-check"></i><b>3.2</b> Pulling and filtering data</a></li>
<li class="chapter" data-level="3.3" data-path="chapter3.html"><a href="chapter3.html#calculation-of-the-growth-contributions"><i class="fa fa-check"></i><b>3.3</b> Calculation of the growth contributions</a></li>
<li class="chapter" data-level="3.4" data-path="chapter3.html"><a href="chapter3.html#graph-of-the-growth-contributions-for-germany"><i class="fa fa-check"></i><b>3.4</b> Graph of the growth contributions for Germany</a></li>
<li class="chapter" data-level="3.5" data-path="chapter3.html"><a href="chapter3.html#average-growth-contributions"><i class="fa fa-check"></i><b>3.5</b> Average growth contributions</a></li>
</ul></li>
<li class="part"><span><b>II Review of math and statistics</b></span></li>
<li class="chapter" data-level="4" data-path="chapter4.html"><a href="chapter4.html"><i class="fa fa-check"></i><b>4</b> Basic math elements</a>
<ul>
<li class="chapter" data-level="4.1" data-path="chapter4.html"><a href="chapter4.html#derivative-rules"><i class="fa fa-check"></i><b>4.1</b> Derivative rules</a></li>
<li class="chapter" data-level="4.2" data-path="chapter4.html"><a href="chapter4.html#matrix-operations"><i class="fa fa-check"></i><b>4.2</b> Matrix operations</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chapter5.html"><a href="chapter5.html"><i class="fa fa-check"></i><b>5</b> Fundamental concepts in statistics</a>
<ul>
<li class="chapter" data-level="5.1" data-path="chapter5.html"><a href="chapter5.html#mean-and-median"><i class="fa fa-check"></i><b>5.1</b> Mean and median</a></li>
<li class="chapter" data-level="5.2" data-path="chapter5.html"><a href="chapter5.html#boxplot"><i class="fa fa-check"></i><b>5.2</b> Boxplot</a></li>
<li class="chapter" data-level="5.3" data-path="chapter5.html"><a href="chapter5.html#expected-value"><i class="fa fa-check"></i><b>5.3</b> Expected value</a></li>
<li class="chapter" data-level="5.4" data-path="chapter5.html"><a href="chapter5.html#variance"><i class="fa fa-check"></i><b>5.4</b> Variance</a></li>
<li class="chapter" data-level="5.5" data-path="chapter5.html"><a href="chapter5.html#correlation"><i class="fa fa-check"></i><b>5.5</b> Correlation</a></li>
<li class="chapter" data-level="5.6" data-path="chapter5.html"><a href="chapter5.html#covariance"><i class="fa fa-check"></i><b>5.6</b> Covariance</a></li>
<li class="chapter" data-level="5.7" data-path="chapter5.html"><a href="chapter5.html#expected-value-variance-and-covariance-rules"><i class="fa fa-check"></i><b>5.7</b> Expected value, variance and covariance rules</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chapter6.html"><a href="chapter6.html"><i class="fa fa-check"></i><b>6</b> Introduction to statistical inference</a>
<ul>
<li class="chapter" data-level="6.1" data-path="chapter6.html"><a href="chapter6.html#the-normal-distribution"><i class="fa fa-check"></i><b>6.1</b> The normal distribution</a></li>
<li class="chapter" data-level="6.2" data-path="chapter6.html"><a href="chapter6.html#the-standard-normal-distribution"><i class="fa fa-check"></i><b>6.2</b> The standard normal distribution</a></li>
</ul></li>
<li class="part"><span><b>III The linear regression</b></span></li>
<li class="chapter" data-level="7" data-path="chapter7.html"><a href="chapter7.html"><i class="fa fa-check"></i><b>7</b> Regression analysis</a>
<ul>
<li class="chapter" data-level="7.1" data-path="chapter7.html"><a href="chapter7.html#simple-regression-model"><i class="fa fa-check"></i><b>7.1</b> Simple regression model</a></li>
<li class="chapter" data-level="7.2" data-path="chapter7.html"><a href="chapter7.html#multiple-regression-model"><i class="fa fa-check"></i><b>7.2</b> Multiple regression model</a></li>
<li class="chapter" data-level="7.3" data-path="chapter7.html"><a href="chapter7.html#regression-assumptions"><i class="fa fa-check"></i><b>7.3</b> Regression assumptions</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="chapter8.html"><a href="chapter8.html"><i class="fa fa-check"></i><b>8</b> Inference</a>
<ul>
<li class="chapter" data-level="8.1" data-path="chapter8.html"><a href="chapter8.html#the-basics-of-hypothesis-testing"><i class="fa fa-check"></i><b>8.1</b> The basics of hypothesis testing</a></li>
<li class="chapter" data-level="8.2" data-path="chapter8.html"><a href="chapter8.html#the-t-test-in-the-regression"><i class="fa fa-check"></i><b>8.2</b> The <em>t</em> test in the regression</a></li>
<li class="chapter" data-level="8.3" data-path="chapter8.html"><a href="chapter8.html#f-statistic-for-overall-significance-of-a-regression"><i class="fa fa-check"></i><b>8.3</b> F statistic for overall significance of a regression</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chapter9.html"><a href="chapter9.html"><i class="fa fa-check"></i><b>9</b> Applications</a>
<ul>
<li class="chapter" data-level="9.1" data-path="chapter9.html"><a href="chapter9.html#linear-growth-model"><i class="fa fa-check"></i><b>9.1</b> Linear growth model</a></li>
<li class="chapter" data-level="9.2" data-path="chapter9.html"><a href="chapter9.html#the-consumption-function"><i class="fa fa-check"></i><b>9.2</b> The consumption function</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/Alessandro1984/Intro_to_quant_methods" target="blank">GitHub repository</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to quantitative methods for economists</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<link href="style.css" rel="stylesheet">
<div class="hero-image-container"> 
  <img class= "hero-image" src="images/fotohero.jpg">
</div>
<div id="chapter6" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">Chapter 6</span> Introduction to statistical inference<a href="chapter6.html#chapter6" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>The basics of hypothesis testing<a href="#fn27" class="footnote-ref" id="fnref27"><sup>27</sup></a></p>
<p>In <strong>descriptive statistics</strong>, we work with a sample of data obtained from a larger population and we are interested in understanding the characteristics of the sample. In <strong>inferential statistics</strong>, we use the sample to try to obtain conclusions (more precisely said, to make inference) regarding the characteristics of the population from which the sample is obtained. For example, having a sample available we might be interested in inferring whether the sample mean (sample statistics, <span class="math inline">\(\bar{x}\)</span>) is representative of the population mean (population parameter, <span class="math inline">\(\mu\)</span>). That is, we are interested in generalising the information obtained from the sample to the entire population. Of course it is easy to imagine that our conclusion will be subject to error as we only have one sample available. With only one sample available, it is very unlikely that the sample mean will be identical to the population mean. So in our inference process we have to take this sampling error into account.</p>
<p>Hypothesis testing is a widely used statistical procedure for making inference from a sample to a population.<a href="#fn28" class="footnote-ref" id="fnref28"><sup>28</sup></a> The test starts with two statements. The <strong>null hypothesis</strong>, denoted <span class="math inline">\(H_0\)</span>. The null hypothesis describes the condition that is assumed to be true at the time. It is often compared to the situation in court where an accused person is assumed to be innocent until there is enough evidence to find him guilty. The second statement is the <strong>alternative hypothesis</strong>, denote <span class="math inline">\(H_1\)</span>. The null hypothesis and the alternative hypothesis are mutually exclusive. The alternative hypothesis is the one that is favoured if enough evidence is found. Many times we have a theory that suggests which values to specify for the null hypothesis and the alternative hypothesis. Hypothesis testing is a means of testing the statistical (not practical) validity of our theory.</p>
<p><span class="math display">\[H_0: \mu = \mu_0\]</span></p>
<p><span class="math display">\[H_1: \mu \neq \mu_0\]</span></p>
<p>How do we decide between the null hypothesis and the alternative hypothesis? We assume that we have a normally distributed random variable <span class="math inline">\(X\)</span> with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>. Let us further assume that the population mean <span class="math inline">\(\mu\)</span> (which we do not know) is a value equal to <span class="math inline">\(\mu_0\)</span> (maybe because theory or experience tells us so). In a first sample obtained from our random variable <span class="math inline">\(X\)</span>, we compute the mean (<span class="math inline">\(\bar{x}\)</span>) and obtain a value close to the hypothesized value <span class="math inline">\(\mu_0\)</span>. Since we know that data are obtained from a normally distributed <span class="math inline">\(X\)</span>, we know that the probability of obtaining a value close to the mean is actually quite high. In a second sample, a much larger value of <span class="math inline">\(\bar{x}\)</span> is obtained. In this case, we know that obtaining values much larger than the mean is less probable (in other words, we are in the tales of the distribution). What should we conclude with such a high value now? Does the sample results confirm or contradict the null hypothesis, i.e. the hypothesized value for the mean of the population? We can continue to believe that the null hypothesis is correct and that we have just an unlucky sample from which we have obtained a very high mean but we are somehow convinced that the hypothesized value is still correct (<span class="math inline">\(H_0: \mu = \mu_0\)</span>) and the sample was just a bit off. Or we can convince ourselves that the sample result contradicts the assumed value <span class="math inline">\(\mu_0\)</span> and that we were wrong with the null hypothesis (therefore, <span class="math inline">\(H_1: \mu \neq \mu_0\)</span>). In the rule, the null hypothesis is rejected if the probability of obtaining such an extreme value is smaller than an arbitrarily defined probability.</p>
<p>There are two kinds of mistakes that can be made. A <strong>Type I error</strong> and a <strong>Type II error</strong>. When we reject a hypothesis that is actually true, we are committing a Type I error. When we are not rejecting (or “accepting”, but this is not the right terminology) a hypothesis that should be rejected, we are committing a Type II error. Since we are basing our decision on a sample, and there is always uncertainty in the sampling process, we are more or less sure that there is some uncertainty attached to our test conclusion. In hypothesis testing we decide in advance what kind of error we want to make. The procedure is to decide in advance to commit to a certain Type I error, e.g. we decide in advance to tolerate a Type I error in 5% of the cases. This value is called <strong>significance level</strong> and is traditionally indicated with the greek letter <span class="math inline">\(\alpha\)</span>.<a href="#fn29" class="footnote-ref" id="fnref29"><sup>29</sup></a></p>
<p><strong>Example</strong></p>
<p>The mean lifetime of a sample of 100 light bulbs is computed to be 1570 hours with a standard deviation of 120 hours. If <span class="math inline">\(\mu\)</span> is the mean lifetime of all the light bulbs produced, test the hypothesis that the population mean is <span class="math inline">\(\mu = 1600\)</span> hours against the alternative that <span class="math inline">\(\mu \neq 1600\)</span> using a significance level of 5%. Find the p-value of the test and build a 95% confidence interval.</p>
<p><span class="math display">\[H_0: \mu = 1600\]</span></p>
<p><span class="math display">\[H_1: \mu \neq \space 1600\]</span></p>
<p>We need to construct our test statistic to perform the test. In practice, wee need to transform the computed mean obtained from the sample of light bulbs into a statistic that follow a standard normal distribution with zero mean and unit variance.</p>
<p><span class="math display">\[z_{test} = \frac{\bar{x} - \mu}{\frac{\sigma}{\sqrt{n}}} = \frac{1570 - 1600}{12} = -2.5\]</span></p>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb175-1"><a href="chapter6.html#cb175-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb175-2"><a href="chapter6.html#cb175-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb175-3"><a href="chapter6.html#cb175-3" aria-hidden="true" tabindex="-1"></a>sample_mean <span class="ot">&lt;-</span> <span class="dv">1570</span></span>
<span id="cb175-4"><a href="chapter6.html#cb175-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb175-5"><a href="chapter6.html#cb175-5" aria-hidden="true" tabindex="-1"></a>sample_sigma <span class="ot">&lt;-</span> <span class="dv">120</span></span>
<span id="cb175-6"><a href="chapter6.html#cb175-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb175-7"><a href="chapter6.html#cb175-7" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="dv">1600</span></span>
<span id="cb175-8"><a href="chapter6.html#cb175-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb175-9"><a href="chapter6.html#cb175-9" aria-hidden="true" tabindex="-1"></a>alpha5p <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb175-10"><a href="chapter6.html#cb175-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb175-11"><a href="chapter6.html#cb175-11" aria-hidden="true" tabindex="-1"></a>z_test <span class="ot">&lt;-</span> <span class="fu">abs</span>((sample_mean <span class="sc">-</span> mu) <span class="sc">/</span> (sample_sigma <span class="sc">/</span> <span class="fu">sqrt</span>(n)))</span>
<span id="cb175-12"><a href="chapter6.html#cb175-12" aria-hidden="true" tabindex="-1"></a>z_test</span></code></pre></div>
<pre><code>## [1] 2.5</code></pre>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="chapter6.html#cb177-1" aria-hidden="true" tabindex="-1"></a>z_crit_5p <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(alpha5p<span class="sc">/</span><span class="dv">2</span>, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p>Since in this exercise we are interested in performing a two-sided test (look a the formulation of the null and alternative hypothesis), we take the absolute value of our <span class="math inline">\(z\)</span> test. We can reject <span class="math inline">\(H_0\)</span> at the 5% significance level (<span class="math inline">\(\alpha\)</span> = 5%) if,</p>
<p><span class="math display">\[|z_{test}| &gt; z_{crit}\]</span></p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="chapter6.html#cb178-1" aria-hidden="true" tabindex="-1"></a>z_test <span class="sc">&gt;</span> z_crit_5p</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>We can reject <span class="math inline">\(H_0\)</span> at the 5% significance level. In the following graph, in green we can see the rejection region (the two green shaded areas add up to 5%) while with the yellow line it is indicated the value of our <span class="math inline">\(z\)</span> test in both tails of the distribution. As we said, since the value of our <span class="math inline">\(z\)</span> test falls within the rejection region, we can reject <span class="math inline">\(H_0\)</span> at the 5% significance level.</p>
<p><img src="Intro_to_quant_methods_files/figure-html/unnamed-chunk-85-1.png" width="70%" height="30%" style="display: block; margin: auto;" /></p>
<p>What do we see highlighted in black in the graph above? The sum of the two black areas represent our p-value for the <em>z</em> score that we have just calculated. We can think of the p-value as the smallest significance level at which we still reject the null hypothesis (or the largest significance level at which the null hypothesis cannot be rejected). How large is the p-value for our <em>z</em> test?</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="chapter6.html#cb180-1" aria-hidden="true" tabindex="-1"></a>pvalue <span class="ot">&lt;-</span> <span class="fu">pnorm</span>(z_test, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>) <span class="sc">*</span> <span class="dv">2</span></span>
<span id="cb180-2"><a href="chapter6.html#cb180-2" aria-hidden="true" tabindex="-1"></a>pvalue<span class="sc">*</span><span class="dv">100</span></span></code></pre></div>
<pre><code>## [1] 1.241933</code></pre>
<p>How can we interpret the p-value? In our exercise, the p-value of 1.24% represents the probability that a mean lifetime of less than 1570 or more than 1630 hours would occur by chance if <span class="math inline">\(H_0\)</span> were actually true. A rather small probability. How did we obtain the values 1570 and 1630? We have used (half) of the p-value to calculate the quantiles of a normal distribution with mean <span class="math inline">\(mu = 1600\)</span> and standard deviation <span class="math inline">\(120/\sqrt{100}\)</span>.</p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="chapter6.html#cb182-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(pvalue<span class="sc">/</span><span class="dv">2</span>, <span class="at">mean =</span> mu, <span class="at">sd =</span> (sample_sigma <span class="sc">/</span> <span class="fu">sqrt</span>(n)), <span class="at">lower.tail =</span> <span class="cn">FALSE</span>) </span></code></pre></div>
<pre><code>## [1] 1630</code></pre>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="chapter6.html#cb184-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(pvalue<span class="sc">/</span><span class="dv">2</span>, <span class="at">mean =</span> mu, <span class="at">sd =</span> (sample_sigma <span class="sc">/</span> <span class="fu">sqrt</span>(n)), <span class="at">lower.tail =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## [1] 1570</code></pre>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="chapter6.html#cb186-1" aria-hidden="true" tabindex="-1"></a>(<span class="fu">pnorm</span>(<span class="dv">1570</span>, <span class="at">mean =</span> mu, <span class="at">sd =</span> (sample_sigma <span class="sc">/</span> <span class="fu">sqrt</span>(n)), <span class="at">lower.tail =</span> <span class="cn">TRUE</span>) <span class="sc">+</span> </span>
<span id="cb186-2"><a href="chapter6.html#cb186-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="dv">1630</span>, <span class="at">mean =</span> mu, <span class="at">sd =</span> (sample_sigma <span class="sc">/</span> <span class="fu">sqrt</span>(n)), <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)) <span class="sc">*</span> <span class="dv">100</span></span></code></pre></div>
<pre><code>## [1] 1.241933</code></pre>
<p>Since we see that the p-value is larger than 1%, we already know that we will fail to reject the null hypothesis at the 1% significance level (<span class="math inline">\(\alpha\)</span> = 1%) . Shouldn’t we have used a <em>t</em> test rather than a <span class="math inline">\(z\)</span> test as suggested by professional statisticians? Probably yes. Since we do not know the population standard deviation (the standard deviation of all light bulbs), a <em>t</em> test sounds more appropriate. However, since our sample is relatively large (<span class="math inline">\(n = 100\)</span>), much larger than the commonly suggested rule of thumb (<span class="math inline">\(n &gt; 30\)</span>), we will practically obtain (almost) the same result using the normal distribution and the <em>t</em> distribution.<a href="#fn30" class="footnote-ref" id="fnref30"><sup>30</sup></a> To conclude, we need to construct the 95% confidence interval (<span class="math inline">\(100 - \alpha\)</span>, where <span class="math inline">\(\alpha\)</span> = 5%).</p>
<p><span class="math display">\[(\bar{x} + z_{\alpha / 2} \cdot \frac{\sigma}{\sqrt{n}}; \bar{x} + z_{1 - \alpha / 2} \cdot \frac{\sigma}{\sqrt{n}})\]</span></p>
<p>We must be careful with the signs in the formula above. Once we look up the critical value <span class="math inline">\(z_{\alpha / 2}\)</span> (or we compute it using R) we will see that the quantity is actually negative. If we include the negative sign in the formula for the confidence interval, it would not be wrong, but it can create some confusion. This is why it is better to use the formula below. In this case, we have to include the negative sign in the formula because <span class="math inline">\(z_{1 - \alpha / 2}\)</span> is going to be a positive number and this is the version that we are going to implement in R.</p>
<p><span class="math display">\[(\bar{x} - z_{1 - \alpha / 2} \cdot \frac{\sigma}{\sqrt{n}}; \bar{x} + z_{1 - \alpha / 2} \cdot \frac{\sigma}{\sqrt{n}})\]</span></p>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb188-1"><a href="chapter6.html#cb188-1" aria-hidden="true" tabindex="-1"></a>sample_mean <span class="sc">+</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="sc">+</span><span class="dv">1</span>) <span class="sc">*</span> z_crit_5p <span class="sc">*</span> (sample_sigma <span class="sc">/</span> <span class="fu">sqrt</span>(n)) </span></code></pre></div>
<pre><code>## [1] 1546.48 1593.52</code></pre>
<p>The hypothesized value for the mean lifetime of all the bulbs produced was 1600 working hours. Since this particular value falls outside the confidence interval constructed around the sample mean, we can reject <span class="math inline">\(H_0\)</span>. With the confidence interval test the null hypothesis is rejected if and only if the hypothesized value falls outside the confidence interval. The <span class="math inline">\(z\)</span> test (or <span class="math inline">\(t\)</span> test) and the confidence interval test are basically an elaboration of one another and provides always the same test decision.<a href="#fn31" class="footnote-ref" id="fnref31"><sup>31</sup></a></p>
<div id="the-normal-distribution" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> The normal distribution<a href="#fn32" class="footnote-ref" id="fnref32"><sup>32</sup></a><a href="chapter6.html#the-normal-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The normal distribution is a common probability distribution in statistics and econometrics (it is just one of many distributions). The normal distribution fits a number of natural and social phenomena. When a phenomenon (a random variable) has a normal distribution, its <strong>probability density function</strong> (for short, PDF) assumes the well-known bell-shaped curve. The normal distribution is sometimes called the Gaussian distribution or the Gauss curve in honor of the famous mathematician Carl-Friedrich Gauss.<a href="#fn33" class="footnote-ref" id="fnref33"><sup>33</sup></a> Shape and position of the normal distribution are entirely determined by mean (<span class="math inline">\(\mu\)</span>) and standard deviation (<span class="math inline">\(\sigma\)</span>) of the normally distributed random variable. This is written as:</p>
<p><span class="math display">\[X \sim Normal(\mu, \sigma)\]</span></p>
<p>For example, we see that the two normal distributions shown in the following graph have the same mean but different standard deviations.</p>
<p><img src="Intro_to_quant_methods_files/figure-html/unnamed-chunk-89-1.png" width="70%" height="30%" style="display: block; margin: auto;" /></p>
<p>The mean determines the location of the normal distribution in the horizontal axis. The majority of the body is located around the mean to which correspond the peak in the distribution. The standard deviation determines the shape of the curve. In practice, it determines how far the values of the variable are from the mean. This means that a higher mean shifts the curve to the right without changing its shape. Similarly, a higher standard deviation widens the body of the curve without shifting its position on the horizontal axis.</p>
<p>The normal distribution has a number of interesting and useful properties. First of all, it is symmetrical with respect to the mean, from which it follows that half of the values are distributed half to the right and half to the left of the mean. Knowing the mean and standard deviation of a certain event or random variable, the normal distribution allows us to calculate the probability that the event will assume a certain value or range of values. Roughly speaking, this correspond to the area below the curve. In reality, this is done using the <strong>cumulative distribution function</strong> (CDF) which is nothing more than the integral of the PDF. The following figure shows the relationship between PDF (left) and CDF (right) of a normally distributed random variable with mean 0 and standard deviation 1.</p>
<p><img src="Intro_to_quant_methods_files/figure-html/unnamed-chunk-90-1.png" width="80%" height="30%" style="display: block; margin: auto;" /></p>
</div>
<div id="the-standard-normal-distribution" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> The standard normal distribution<a href="chapter6.html#the-standard-normal-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A special case of normal distribution is the standard normal distribution where the mean is equal to 0 and the standard deviation is equal to 1 (this is actually what we used in the previous exercise but we had not yet used this term). Let us now see how it is possible to “standardise a variable”. This is a very important procedure that we will see again later when we talk about hypothesis testing. In the following section we will instead use it to calculate the so-called <span class="math inline">\(z\)</span> scores.</p>
<p><span class="math display">\[Z = \frac{X - \mu}{\sigma}\]</span></p>
<p>Rewriting <span class="math inline">\(Z\)</span> as <span class="math inline">\(aX + b\)</span>, where <span class="math inline">\(a = (1/\sigma)\)</span> and <span class="math inline">\(b = -(\mu/\sigma)\)</span> and using the properties of expectation and variance we can see that:</p>
<p><span class="math display">\[E(Z) = aE(X) + b = (\mu/\sigma) - (\mu/\sigma) = 0\]</span></p>
<p><span class="math display">\[Var(Z) = a^2Var(X) = (\sigma^2/\sigma^2) = 1\]</span></p>
<p>What does that mean? It means that if we subtract the mean from a variable (<span class="math inline">\(X\)</span>) and divide it by the standard deviation we will have a standardised variable (<span class="math inline">\(Z\)</span>) that has a mean of zero and standard deviation of 1.</p>
<p><strong>Exercises</strong></p>
<ol style="list-style-type: decimal">
<li>We are given the following set of numbers: <span class="math inline">\(6, 2 , 8, 7, 5\)</span>. Transform the set into standard scores and check that mean and standard deviation of the transformed set are respectively 0 and 1.</li>
</ol>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb190-1"><a href="chapter6.html#cb190-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">6</span>, <span class="dv">2</span> , <span class="dv">8</span>, <span class="dv">7</span>, <span class="dv">5</span>)</span>
<span id="cb190-2"><a href="chapter6.html#cb190-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb190-3"><a href="chapter6.html#cb190-3" aria-hidden="true" tabindex="-1"></a>mean_x <span class="ot">&lt;-</span> <span class="fu">mean</span>(x)</span>
<span id="cb190-4"><a href="chapter6.html#cb190-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb190-5"><a href="chapter6.html#cb190-5" aria-hidden="true" tabindex="-1"></a>sd_x <span class="ot">&lt;-</span> <span class="fu">sd</span>(x)</span>
<span id="cb190-6"><a href="chapter6.html#cb190-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb190-7"><a href="chapter6.html#cb190-7" aria-hidden="true" tabindex="-1"></a>z <span class="ot">&lt;-</span> (x <span class="sc">-</span> mean_x)<span class="sc">/</span>sd_x</span>
<span id="cb190-8"><a href="chapter6.html#cb190-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb190-9"><a href="chapter6.html#cb190-9" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(z)</span></code></pre></div>
<pre><code>## [1] 1.387779e-16</code></pre>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb192-1"><a href="chapter6.html#cb192-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(z)</span></code></pre></div>
<pre><code>## [1] 1</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Let us assume that the random variable <span class="math inline">\(X\)</span> is a normally distributed random variable with mean (<span class="math inline">\(\mu\)</span>) equal to 5 and population standard deviation (<span class="math inline">\(\sigma\)</span>) equal to 4. In short, <span class="math inline">\(Normal ~ (5,4)\)</span>. Calculate the probabilities that our random variable <span class="math inline">\(X\)</span> assume a value smaller than 6, <span class="math inline">\(P(X \leq 6)\)</span>, using the table of the standard normal probabilities or R (much better!).</li>
</ol>
<p>If we did not have R available we would have to find the <span class="math inline">\(z\)</span> score corresponding to the value of interest, 6 in this case, and look in the table of standard normal probabilities (the area below the curve) the probability that our random variable assumes a value smaller than that.<a href="#fn34" class="footnote-ref" id="fnref34"><sup>34</sup></a></p>
<div class="sourceCode" id="cb194"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb194-1"><a href="chapter6.html#cb194-1" aria-hidden="true" tabindex="-1"></a>mu_x <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb194-2"><a href="chapter6.html#cb194-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb194-3"><a href="chapter6.html#cb194-3" aria-hidden="true" tabindex="-1"></a>sigma_x <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb194-4"><a href="chapter6.html#cb194-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb194-5"><a href="chapter6.html#cb194-5" aria-hidden="true" tabindex="-1"></a>z <span class="ot">&lt;-</span> (<span class="dv">6</span> <span class="sc">-</span> mu_x) <span class="sc">/</span> sigma_x</span>
<span id="cb194-6"><a href="chapter6.html#cb194-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb194-7"><a href="chapter6.html#cb194-7" aria-hidden="true" tabindex="-1"></a>z </span></code></pre></div>
<pre><code>## [1] 0.25</code></pre>
<p><span class="math display">\[z = \frac{6 - 5}{4} = 0.25\]</span></p>
<p>Our <span class="math inline">\(z\)</span> value of interest is 0.25. The probability that the variable <span class="math inline">\(X\)</span> takes on a value less than 6 is given by the area under the normal curve to the left of <span class="math inline">\(z = 0.25\)</span>. This value is equal to:</p>
<div class="sourceCode" id="cb196"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb196-1"><a href="chapter6.html#cb196-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(z, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>, <span class="at">lower.tail =</span> <span class="cn">TRUE</span>)<span class="sc">*</span><span class="dv">100</span></span></code></pre></div>
<pre><code>## [1] 59.87063</code></pre>
<p>We can achieve the same result by using the <em>lower.tail = FALSE</em> option. In this case we get the white area in the graph below and will have to subtract this quantity from 1 or 100%, i.e. the whole area under the curve.</p>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb198-1"><a href="chapter6.html#cb198-1" aria-hidden="true" tabindex="-1"></a><span class="dv">100</span> <span class="sc">-</span> <span class="fu">pnorm</span>(z, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)<span class="sc">*</span><span class="dv">100</span></span></code></pre></div>
<pre><code>## [1] 59.87063</code></pre>
<p>In the graph below, the area marked in green indicates the probability that the independent variable <span class="math inline">\(X\)</span> takes on a value less than 6 given mean and population standard deviation of 5 and 4, respectively.</p>
<p><img src="Intro_to_quant_methods_files/figure-html/unnamed-chunk-95-1.png" width="70%" height="30%" style="display: block; margin: auto;" /></p>
<p>If we have software at our disposal we do not have to use tables. In this case there is no need to calculate the <span class="math inline">\(z\)</span> score. The result (and the graph) will be exactly the same with the important difference that now the values reported in the horizontal axis will be the values of <span class="math inline">\(X\)</span> and not the standardized scores.</p>
<pre><code>## [1] 59.87063</code></pre>
<p><img src="Intro_to_quant_methods_files/figure-html/unnamed-chunk-96-1.png" width="70%" height="30%" style="display: block; margin: auto;" /></p>
<ol start="3" style="list-style-type: decimal">
<li><p>The test scores for a class of students (this is the population) are normally distributed with mean (<span class="math inline">\(\mu\)</span>) equal to 75 points and standard deviation (<span class="math inline">\(\sigma\)</span>) equal to 10 points. What is the probability that a students scores above 80 points?</p></li>
<li><p>Calculate the following probabilities:</p></li>
</ol>
<ul>
<li>Given <span class="math inline">\(X \sim Normal(3,4)\)</span>, find <span class="math inline">\(P(X \leq 1)\)</span></li>
<li>Given <span class="math inline">\(X \sim Normal(4,0)\)</span>, find <span class="math inline">\(P(2 &lt; X \leq 6)\)</span></li>
</ul>

</div>
</div>



<div class="footnotes">
<hr />
<ol start="27">
<li id="fn27"><p>The discussion presented here is based on Wooldridge, J. Introductory Econometrics: A Modern Approach (Chapter 4 and Appendix C) and Dougherty, C. Introduction to Econometrics (Review chapter).<a href="chapter6.html#fnref27" class="footnote-back">↩︎</a></p></li>
<li id="fn28"><p>This procedure is part of the branch of statistics called <em>parametric statistics</em>. In fact, it is assumed that the population from which the sample is obtained follows some kind of distribution (<span class="math inline">\(t\)</span> distribution, normal distribution, <span class="math inline">\(F\)</span> distribution) to which reference will be made to compare the plausibility of the sample statistics. Another branch of statistics is called <em>non-parametric</em> and does not assume any kind of distribution.<a href="chapter6.html#fnref28" class="footnote-back">↩︎</a></p></li>
<li id="fn29"><p>Again, <span class="math inline">\(\alpha\)</span> is the probability of rejecting a true null hypothesis. Traditionally in econometrics, we use three levels of significance 10%, 5% and 1%.<a href="chapter6.html#fnref29" class="footnote-back">↩︎</a></p></li>
<li id="fn30"><p>
If we want to see why this is the case, take a look <a href="https://rpsychologist.com/d3/tdist/">here</a>.<a href="chapter6.html#fnref30" class="footnote-back">↩︎</a></p></li>
<li id="fn31"><p>
For common misunderstandings about the confidence interval, see <a href="https://en.wikipedia.org/wiki/Confidence_interval">here</a>.<a href="chapter6.html#fnref31" class="footnote-back">↩︎</a></p></li>
<li id="fn32"><p>The discussion presented here and in particular the proof of mean and standard deviation of the the standardized random variable rely on Wooldridge, J. Introductory Econometrics: A Modern Approach (Appendix C).<a href="chapter6.html#fnref32" class="footnote-back">↩︎</a></p></li>
<li id="fn33"><p>At first glance, many phenomena do not appear to follow a normal distribution. However, after a logarithmic transformation they assume a (log)normal distribution.<a href="chapter6.html#fnref33" class="footnote-back">↩︎</a></p></li>
<li id="fn34"><p>Since the normal distribution is continuous, <span class="math inline">\(P(Z &lt; z) = P(Z \leq z)\)</span>.<a href="chapter6.html#fnref34" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapter5.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chapter7.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Intro_to_quant_methods.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
